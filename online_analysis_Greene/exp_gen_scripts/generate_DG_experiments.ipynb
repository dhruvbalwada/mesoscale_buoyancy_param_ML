{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788552bb-b4cf-46d4-b440-e547b0da310e",
   "metadata": {},
   "source": [
    "# Double Gyre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7a55fd-5b59-439a-9ff1-97886912916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6dfefa-3c66-4944-868b-78324a0f97e9",
   "metadata": {},
   "source": [
    "### Parameters we want altered :\n",
    "\n",
    "In MOM_override\n",
    "For P2L \n",
    "- NIGLOBAL (220, 110, 55, 27) (total lenx = 2200)\n",
    "- NJGLOBAL (200, 100, 50, 25) (total leny = 2000)\n",
    "- thickness_flux_model_type (\"nondim_ANN\" or \"GM ann\")\n",
    "- thickness_flux_ann_num_layers (4 or 2)\n",
    "- thickness_flux_ann_params_file (\"INPUT/main_ANN_window_3.nc\" or \"INPUT/thickness_diffuse_k1000_ann_params.nc\")\n",
    "- thickness_flux_ann_coeff (0 -> 1)\n",
    "\n",
    "\n",
    "In mom.sub \n",
    "- #SBATCH --job-name=\"MOM6\" to #SBATCH --job-name=\"<whatever is right name here.>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81924664-bb00-44f2-9c74-4f5d68b2a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [10, 20, 40, 80]\n",
    "C_ANN = np.array([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "C_GM = np.array([10, 50, 100, 200, 500])/1000\n",
    "model_types = ['ANN', 'GM1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27bfd88c-4dcb-469b-85cf-80ba7f6dfb3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate exp P2L \n",
    "\n",
    "Lx = 2200\n",
    "Ly = 2000\n",
    "\n",
    "exp_dic = {}\n",
    "for ANN_type in model_types:\n",
    "    for r in res: \n",
    "        NIGLOBAL = int(Lx/r)\n",
    "        NJGLOBAL = int(Ly/r)\n",
    "        \n",
    "        if ANN_type == 'ANN': \n",
    "            C = C_ANN\n",
    "            model_type = 'nondim_ann'\n",
    "            num_layers = 4\n",
    "            param_file = \"INPUT/main_ANN_window_3.nc\"\n",
    "            \n",
    "        elif ANN_type == 'GM1000':\n",
    "            C = C_GM \n",
    "            model_type = 'GM_ann'\n",
    "            num_layers = 2\n",
    "            param_file = \"INPUT/thickness_diffuse_k1000_ann_params.nc\"\n",
    "        \n",
    "        for coeff in C: \n",
    "    \n",
    "            exp_name = 'res_' + str(r) + 'km_' + str(ANN_type) + '_' + str(coeff)\n",
    "            # print(exp_name)\n",
    "            \n",
    "            exp_dic[exp_name] = {}\n",
    "            \n",
    "            exp_dic[exp_name]['MOM_override_params'] = {'NIGLOBAL': NIGLOBAL, \n",
    "                                                        'NJGLOBAL': NJGLOBAL,\n",
    "                                                        'DAYMAX' : 14400.,\n",
    "                                                        'thickness_flux_model_type': model_type,\n",
    "                                                        'thickness_flux_ann_num_layers': num_layers,\n",
    "                                                        'thickness_flux_ann_params_file': param_file,\n",
    "                                                        'thickness_flux_ann_coeff': coeff} \n",
    "\n",
    "            exp_dic[exp_name]['mom.sub_params'] = {'--job-name': exp_name,\n",
    "                                                   '--time': '03:00:00'} \n",
    "\n",
    "            if r>40: \n",
    "                exp_dic[exp_name]['mom.sub_params'] = {'--job-name': exp_name,\n",
    "                                                      '--time': '01:00:00', \n",
    "                                                      '--ntasks-per-node': 16} \n",
    "            if r<20:\n",
    "                exp_dic[exp_name]['mom.sub_params'] = {'--job-name': exp_name,\n",
    "                                                      '--time': '09:00:00', \n",
    "                                                      '--ntasks-per-node': 48}\n",
    "\n",
    "            exp_dic[exp_name]['input.nml_params'] = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e8744e-f8e5-4cc6-ae79-e370f08a93be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [to_serializable(v) for v in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(to_serializable(v) for v in obj)\n",
    "    elif isinstance(obj, np.generic):\n",
    "        return obj.item()  # convert numpy scalar to Python scalar\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e85b5b-e4e4-4b80-9eee-20d46bc74f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiments_DG_40year.yaml\", \"w\") as f:\n",
    "    yaml.dump({\"experiments\": to_serializable(exp_dic)}, f, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce41df35-b7c0-4906-9570-0b706024e0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3755cbe-8224-42e4-a319-073f6d807074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59bb74-39f8-44e7-857a-e7ec4e562b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2dfe53-3549-419f-ba01-7a20076cad99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e07bb-295c-45ae-9d87-0c33b12646e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17e9530e-ef5a-4490-a849-e396794bac8a",
   "metadata": {},
   "source": [
    "## Code that was used to create the experiment runner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b07d6528-d886-44c5-853c-84e1bf02f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_file=\"experiments.yaml\"):\n",
    "     with open(config_file, \"r\") as f:\n",
    "         return yaml.safe_load(f)[\"experiments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15f49718-f623-4fe5-a28a-df6cc36b1e56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'res_10km_ANN_0.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 120,\n",
       "   'NJGLOBAL': 160,\n",
       "   'thickness_flux_ann_coeff': 0.0,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_10km_ANN_0.0', '--time': '00:03:00'}},\n",
       " 'res_10km_ANN_0.25': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 120,\n",
       "   'NJGLOBAL': 160,\n",
       "   'thickness_flux_ann_coeff': 0.25,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_10km_ANN_0.25', '--time': '00:03:00'}},\n",
       " 'res_10km_ANN_0.5': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 120,\n",
       "   'NJGLOBAL': 160,\n",
       "   'thickness_flux_ann_coeff': 0.5,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_10km_ANN_0.5', '--time': '00:03:00'}},\n",
       " 'res_10km_ANN_0.75': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 120,\n",
       "   'NJGLOBAL': 160,\n",
       "   'thickness_flux_ann_coeff': 0.75,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_10km_ANN_0.75', '--time': '00:03:00'}},\n",
       " 'res_10km_ANN_1.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 120,\n",
       "   'NJGLOBAL': 160,\n",
       "   'thickness_flux_ann_coeff': 1.0,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_10km_ANN_1.0', '--time': '00:03:00'}},\n",
       " 'res_10km_GM1000_0.01': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 120,\n",
       "   'NJGLOBAL': 160,\n",
       "   'thickness_flux_ann_coeff': 0.01,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_10km_GM1000_0.01',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_10km_GM1000_0.05': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 120,\n",
       "   'NJGLOBAL': 160,\n",
       "   'thickness_flux_ann_coeff': 0.05,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_10km_GM1000_0.05',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_10km_GM1000_0.1': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 120,\n",
       "   'NJGLOBAL': 160,\n",
       "   'thickness_flux_ann_coeff': 0.1,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_10km_GM1000_0.1',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_10km_GM1000_0.5': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 120,\n",
       "   'NJGLOBAL': 160,\n",
       "   'thickness_flux_ann_coeff': 0.5,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_10km_GM1000_0.5',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_10km_GM1000_1.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 120,\n",
       "   'NJGLOBAL': 160,\n",
       "   'thickness_flux_ann_coeff': 1.0,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_10km_GM1000_1.0',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_20km_ANN_0.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 60,\n",
       "   'NJGLOBAL': 80,\n",
       "   'thickness_flux_ann_coeff': 0.0,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_20km_ANN_0.0', '--time': '00:03:00'}},\n",
       " 'res_20km_ANN_0.25': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 60,\n",
       "   'NJGLOBAL': 80,\n",
       "   'thickness_flux_ann_coeff': 0.25,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_20km_ANN_0.25', '--time': '00:03:00'}},\n",
       " 'res_20km_ANN_0.5': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 60,\n",
       "   'NJGLOBAL': 80,\n",
       "   'thickness_flux_ann_coeff': 0.5,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_20km_ANN_0.5', '--time': '00:03:00'}},\n",
       " 'res_20km_ANN_0.75': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 60,\n",
       "   'NJGLOBAL': 80,\n",
       "   'thickness_flux_ann_coeff': 0.75,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_20km_ANN_0.75', '--time': '00:03:00'}},\n",
       " 'res_20km_ANN_1.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 60,\n",
       "   'NJGLOBAL': 80,\n",
       "   'thickness_flux_ann_coeff': 1.0,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_20km_ANN_1.0', '--time': '00:03:00'}},\n",
       " 'res_20km_GM1000_0.01': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 60,\n",
       "   'NJGLOBAL': 80,\n",
       "   'thickness_flux_ann_coeff': 0.01,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_20km_GM1000_0.01',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_20km_GM1000_0.05': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 60,\n",
       "   'NJGLOBAL': 80,\n",
       "   'thickness_flux_ann_coeff': 0.05,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_20km_GM1000_0.05',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_20km_GM1000_0.1': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 60,\n",
       "   'NJGLOBAL': 80,\n",
       "   'thickness_flux_ann_coeff': 0.1,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_20km_GM1000_0.1',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_20km_GM1000_0.5': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 60,\n",
       "   'NJGLOBAL': 80,\n",
       "   'thickness_flux_ann_coeff': 0.5,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_20km_GM1000_0.5',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_20km_GM1000_1.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 60,\n",
       "   'NJGLOBAL': 80,\n",
       "   'thickness_flux_ann_coeff': 1.0,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_20km_GM1000_1.0',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_40km_ANN_0.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 30,\n",
       "   'NJGLOBAL': 40,\n",
       "   'thickness_flux_ann_coeff': 0.0,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_40km_ANN_0.0', '--time': '00:03:00'}},\n",
       " 'res_40km_ANN_0.25': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 30,\n",
       "   'NJGLOBAL': 40,\n",
       "   'thickness_flux_ann_coeff': 0.25,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_40km_ANN_0.25', '--time': '00:03:00'}},\n",
       " 'res_40km_ANN_0.5': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 30,\n",
       "   'NJGLOBAL': 40,\n",
       "   'thickness_flux_ann_coeff': 0.5,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_40km_ANN_0.5', '--time': '00:03:00'}},\n",
       " 'res_40km_ANN_0.75': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 30,\n",
       "   'NJGLOBAL': 40,\n",
       "   'thickness_flux_ann_coeff': 0.75,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_40km_ANN_0.75', '--time': '00:03:00'}},\n",
       " 'res_40km_ANN_1.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 30,\n",
       "   'NJGLOBAL': 40,\n",
       "   'thickness_flux_ann_coeff': 1.0,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_40km_ANN_1.0', '--time': '00:03:00'}},\n",
       " 'res_40km_GM1000_0.01': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 30,\n",
       "   'NJGLOBAL': 40,\n",
       "   'thickness_flux_ann_coeff': 0.01,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_40km_GM1000_0.01',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_40km_GM1000_0.05': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 30,\n",
       "   'NJGLOBAL': 40,\n",
       "   'thickness_flux_ann_coeff': 0.05,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_40km_GM1000_0.05',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_40km_GM1000_0.1': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 30,\n",
       "   'NJGLOBAL': 40,\n",
       "   'thickness_flux_ann_coeff': 0.1,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_40km_GM1000_0.1',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_40km_GM1000_0.5': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 30,\n",
       "   'NJGLOBAL': 40,\n",
       "   'thickness_flux_ann_coeff': 0.5,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_40km_GM1000_0.5',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_40km_GM1000_1.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 30,\n",
       "   'NJGLOBAL': 40,\n",
       "   'thickness_flux_ann_coeff': 1.0,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_40km_GM1000_1.0',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_80km_ANN_0.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 15,\n",
       "   'NJGLOBAL': 20,\n",
       "   'thickness_flux_ann_coeff': 0.0,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_80km_ANN_0.0', '--time': '00:03:00'}},\n",
       " 'res_80km_ANN_0.25': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 15,\n",
       "   'NJGLOBAL': 20,\n",
       "   'thickness_flux_ann_coeff': 0.25,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_80km_ANN_0.25', '--time': '00:03:00'}},\n",
       " 'res_80km_ANN_0.5': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 15,\n",
       "   'NJGLOBAL': 20,\n",
       "   'thickness_flux_ann_coeff': 0.5,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_80km_ANN_0.5', '--time': '00:03:00'}},\n",
       " 'res_80km_ANN_0.75': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 15,\n",
       "   'NJGLOBAL': 20,\n",
       "   'thickness_flux_ann_coeff': 0.75,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_80km_ANN_0.75', '--time': '00:03:00'}},\n",
       " 'res_80km_ANN_1.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 15,\n",
       "   'NJGLOBAL': 20,\n",
       "   'thickness_flux_ann_coeff': 1.0,\n",
       "   'thickness_flux_ann_num_layers': 4,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/main_ANN_window_3.nc',\n",
       "   'thickness_flux_model_type': 'nondim_ANN'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_80km_ANN_1.0', '--time': '00:03:00'}},\n",
       " 'res_80km_GM1000_0.01': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 15,\n",
       "   'NJGLOBAL': 20,\n",
       "   'thickness_flux_ann_coeff': 0.01,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_80km_GM1000_0.01',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_80km_GM1000_0.05': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 15,\n",
       "   'NJGLOBAL': 20,\n",
       "   'thickness_flux_ann_coeff': 0.05,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_80km_GM1000_0.05',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_80km_GM1000_0.1': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 15,\n",
       "   'NJGLOBAL': 20,\n",
       "   'thickness_flux_ann_coeff': 0.1,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_80km_GM1000_0.1',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_80km_GM1000_0.5': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 15,\n",
       "   'NJGLOBAL': 20,\n",
       "   'thickness_flux_ann_coeff': 0.5,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_80km_GM1000_0.5',\n",
       "   '--time': '00:03:00'}},\n",
       " 'res_80km_GM1000_1.0': {'MOM_override_params': {'DAYMAX': 1.0,\n",
       "   'NIGLOBAL': 15,\n",
       "   'NJGLOBAL': 20,\n",
       "   'thickness_flux_ann_coeff': 1.0,\n",
       "   'thickness_flux_ann_num_layers': 2,\n",
       "   'thickness_flux_ann_params_file': 'INPUT/thickness_diffuse_k1000_ann_params.nc',\n",
       "   'thickness_flux_model_type': 'GM_ann'},\n",
       "  'input.nml_params': {},\n",
       "  'mom.sub_params': {'--job-name': 'res_80km_GM1000_1.0',\n",
       "   '--time': '00:03:00'}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2e03f4f-4e94-4a86-88c7-8b14ff95151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def backup_run_dir(src_dir, backup_root, exp_name):\n",
    "    \"\"\"\n",
    "    Copy the existing run directory to a backup location with a timestamp.\n",
    "    \"\"\"\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    backup_dir = os.path.join(backup_root, f\"{exp_name}_{timestamp}\")\n",
    "    shutil.copytree(src_dir, backup_dir)\n",
    "    print(f\"[ðŸ’¾] Backed up {exp_name} to {backup_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "275060bd-1797-4bb2-93fb-52481ff44ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_kv_lines(\n",
    "    base_text,\n",
    "    overrides,\n",
    "    prefix=\"\",\n",
    "    assign_op=\"=\",\n",
    "    comment_prefix=None,\n",
    "    quote_keys=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    General key=value merger with optional smart quoting.\n",
    "    \n",
    "    Parameters:\n",
    "        base_text       : str (original file contents)\n",
    "        overrides       : dict (key: value pairs to override or add)\n",
    "        prefix          : str (text before the key, e.g. '#override ')\n",
    "        assign_op       : str (e.g. '=', ':')\n",
    "        comment_prefix  : str or None â€” restricts which lines to consider\n",
    "        quote_keys      : set of keys â€” only these keys will be quoted if values are strings\n",
    "\n",
    "    Returns:\n",
    "        str : modified file content\n",
    "    \"\"\"\n",
    "\n",
    "    def format_value(key, val):\n",
    "        if isinstance(val, str):\n",
    "            if (quote_keys is None or key in quote_keys):\n",
    "                if not (val.startswith('\"') and val.endswith('\"')):\n",
    "                    return f'\"{val}\"'\n",
    "        return val\n",
    "\n",
    "    lines = base_text.splitlines()\n",
    "    updated = []\n",
    "    keys = set(overrides.keys())\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        use_line = True\n",
    "\n",
    "        if comment_prefix is None or stripped.startswith(comment_prefix):\n",
    "            if prefix in stripped and assign_op in stripped:\n",
    "                content = stripped.replace(prefix, \"\", 1).strip()\n",
    "                key = content.split(assign_op, 1)[0].strip()\n",
    "\n",
    "                if key in overrides:\n",
    "                    val = format_value(key, overrides[key])\n",
    "                    updated.append(f\"{prefix}{key} {assign_op} {val}\")\n",
    "                    keys.remove(key)\n",
    "                    use_line = False\n",
    "\n",
    "        if use_line:\n",
    "            updated.append(line)\n",
    "\n",
    "    for key in keys:\n",
    "        val = format_value(key, overrides[key])\n",
    "        updated.append(f\"{prefix}{key} {assign_op} {val}\")\n",
    "\n",
    "    return \"\\n\".join(updated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cfb8d7b-86cf-4c54-968a-8081eb4a9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_experiment(\n",
    "    name,\n",
    "    config,\n",
    "    mode=\"fresh\",\n",
    "    update_submission_script_flag=False,\n",
    "    update_input_nml_flag=False,\n",
    "    backup_root=None \n",
    "):\n",
    "    run_dir = os.path.join(RUNS_DIR, name)\n",
    "    override_path = os.path.join(run_dir, \"MOM_override\")\n",
    "    momsub_path = os.path.join(run_dir, \"mom.sub\")\n",
    "    nml_path = os.path.join(run_dir, \"input.nml\")\n",
    "\n",
    "    # Handle run directory creation/update\n",
    "    if os.path.exists(run_dir):\n",
    "        if mode == \"skip\":\n",
    "            print(f\"[â­] Skipping existing: {name}\")\n",
    "            return\n",
    "        elif mode == \"fresh\":\n",
    "            shutil.rmtree(run_dir)\n",
    "            shutil.copytree(BASE_DIR, run_dir)\n",
    "        elif mode == \"update\":\n",
    "            # ðŸ”’ Safety: backup before update\n",
    "            if backup_root is not None:\n",
    "                os.makedirs(backup_root, exist_ok=True)\n",
    "                backup_run_dir(run_dir, backup_root, name)\n",
    "            # Don't modify files just yet â€” rest of logic follows\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode: {mode}\")\n",
    "    else:\n",
    "        shutil.copytree(BASE_DIR, run_dir)\n",
    "\n",
    "    # === MOM_override ===\n",
    "    mom_override_cfg = config.get(\"MOM_override_params\", {})\n",
    "    if os.path.exists(override_path):\n",
    "        with open(override_path, \"r\") as f:\n",
    "            base_override = f.read()\n",
    "    else:\n",
    "        base_override = \"\"\n",
    "    override_text = merge_kv_lines(base_override, mom_override_cfg, prefix=\"#override \", assign_op=\"=\", comment_prefix=\"#override\")\n",
    "    with open(override_path, \"w\") as f:\n",
    "        f.write(\"! Auto-generated MOM_override\\n\" + override_text)\n",
    "\n",
    "    # === mom.sub ===\n",
    "    if update_submission_script_flag:\n",
    "        mom_sub_cfg = config.get(\"mom.sub_params\", {})\n",
    "        if os.path.exists(momsub_path):\n",
    "            with open(momsub_path, \"r\") as f:\n",
    "                base_sub = f.read()\n",
    "        else:\n",
    "            base_sub = \"\"\n",
    "        sub_text = merge_kv_lines(base_sub, mom_sub_cfg, prefix=\"#SBATCH \", assign_op=\"=\", comment_prefix=\"#SBATCH\", quote_keys={\"--job-name\"})\n",
    "        with open(momsub_path, \"w\") as f:\n",
    "            f.write(sub_text)\n",
    "\n",
    "    # === input.nml ===\n",
    "    if update_input_nml_flag and \"input.nml_params\" in config:\n",
    "        nml_cfg = config[\"input.nml_params\"]\n",
    "        if os.path.exists(nml_path):\n",
    "            with open(nml_path, \"r\") as f:\n",
    "                base_nml = f.read()\n",
    "        else:\n",
    "            base_nml = \"\"\n",
    "        nml_text = merge_kv_lines(base_nml, nml_cfg, prefix=\"\", assign_op=\"=\", comment_prefix=None)\n",
    "        with open(nml_path, \"w\") as f:\n",
    "            f.write(nml_text)\n",
    "\n",
    "    print(f\"[âœ“] Prepared ({mode}): {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ff7c913-1435-4063-8fad-7300f4bbb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_experiments(mode=\"fresh\", \n",
    "                            backup_root=None,\n",
    "                            update_submission_script_flag=False, \n",
    "                            update_input_nml_flag=False,\n",
    "                            ):\n",
    "    \n",
    "    experiments = load_config()\n",
    "    os.makedirs(RUNS_DIR, exist_ok=True)\n",
    "    \n",
    "    for name, config in experiments.items():\n",
    "        prepare_experiment(\n",
    "            name,\n",
    "            config,\n",
    "            mode=mode,\n",
    "            update_submission_script_flag=update_submission_script_flag,\n",
    "            update_input_nml_flag=update_input_nml_flag,\n",
    "            backup_root = backup_root\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bb7179a-3e34-4dcd-929c-927baa7edf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ“] Prepared (fresh): res_10km_ANN_0.0\n",
      "[âœ“] Prepared (fresh): res_10km_ANN_0.25\n",
      "[âœ“] Prepared (fresh): res_10km_ANN_0.5\n",
      "[âœ“] Prepared (fresh): res_10km_ANN_0.75\n",
      "[âœ“] Prepared (fresh): res_10km_ANN_1.0\n",
      "[âœ“] Prepared (fresh): res_10km_GM1000_0.01\n",
      "[âœ“] Prepared (fresh): res_10km_GM1000_0.05\n",
      "[âœ“] Prepared (fresh): res_10km_GM1000_0.1\n",
      "[âœ“] Prepared (fresh): res_10km_GM1000_0.5\n",
      "[âœ“] Prepared (fresh): res_10km_GM1000_1.0\n",
      "[âœ“] Prepared (fresh): res_20km_ANN_0.0\n",
      "[âœ“] Prepared (fresh): res_20km_ANN_0.25\n",
      "[âœ“] Prepared (fresh): res_20km_ANN_0.5\n",
      "[âœ“] Prepared (fresh): res_20km_ANN_0.75\n",
      "[âœ“] Prepared (fresh): res_20km_ANN_1.0\n",
      "[âœ“] Prepared (fresh): res_20km_GM1000_0.01\n",
      "[âœ“] Prepared (fresh): res_20km_GM1000_0.05\n",
      "[âœ“] Prepared (fresh): res_20km_GM1000_0.1\n",
      "[âœ“] Prepared (fresh): res_20km_GM1000_0.5\n",
      "[âœ“] Prepared (fresh): res_20km_GM1000_1.0\n",
      "[âœ“] Prepared (fresh): res_40km_ANN_0.0\n",
      "[âœ“] Prepared (fresh): res_40km_ANN_0.25\n",
      "[âœ“] Prepared (fresh): res_40km_ANN_0.5\n",
      "[âœ“] Prepared (fresh): res_40km_ANN_0.75\n",
      "[âœ“] Prepared (fresh): res_40km_ANN_1.0\n",
      "[âœ“] Prepared (fresh): res_40km_GM1000_0.01\n",
      "[âœ“] Prepared (fresh): res_40km_GM1000_0.05\n",
      "[âœ“] Prepared (fresh): res_40km_GM1000_0.1\n",
      "[âœ“] Prepared (fresh): res_40km_GM1000_0.5\n",
      "[âœ“] Prepared (fresh): res_40km_GM1000_1.0\n",
      "[âœ“] Prepared (fresh): res_80km_ANN_0.0\n",
      "[âœ“] Prepared (fresh): res_80km_ANN_0.25\n",
      "[âœ“] Prepared (fresh): res_80km_ANN_0.5\n",
      "[âœ“] Prepared (fresh): res_80km_ANN_0.75\n",
      "[âœ“] Prepared (fresh): res_80km_ANN_1.0\n",
      "[âœ“] Prepared (fresh): res_80km_GM1000_0.01\n",
      "[âœ“] Prepared (fresh): res_80km_GM1000_0.05\n",
      "[âœ“] Prepared (fresh): res_80km_GM1000_0.1\n",
      "[âœ“] Prepared (fresh): res_80km_GM1000_0.5\n",
      "[âœ“] Prepared (fresh): res_80km_GM1000_1.0\n"
     ]
    }
   ],
   "source": [
    "generate_all_experiments(update_submission_script_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37dd5368-240e-433d-acd7-a27e02833cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def submit_and_log_job(run_dir, exp_name, log_path=\"submitted_jobs.csv\"):\n",
    "    result = subprocess.run(\n",
    "        [\"sbatch\", \"mom.sub\"],\n",
    "        cwd=run_dir,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        output = result.stdout.strip()\n",
    "        print(f\"[ðŸš€] Submitted {exp_name}: {output}\")\n",
    "\n",
    "        if \"Submitted batch job\" in output:\n",
    "            job_id = output.split()[-1]\n",
    "\n",
    "            # Append to CSV log\n",
    "            with open(log_path, \"a\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([timestamp, exp_name, job_id, run_dir])\n",
    "\n",
    "            return job_id\n",
    "    else:\n",
    "        print(f\"[âŒ] Submission failed for {exp_name}: {result.stderr.strip()}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaa4a05a-78e8-4aaa-afb9-e98dc6a3d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_experiments_with_tracking(runs_root=\"runs\", log_path=\"submitted_jobs.csv\"):\n",
    "    # If the log doesn't exist yet, create it with a header\n",
    "    if not os.path.exists(log_path):\n",
    "        with open(log_path, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"timestamp\", \"experiment\", \"job_id\", \"path\"])\n",
    "\n",
    "    for exp_name in sorted(os.listdir(runs_root)):\n",
    "        run_dir = os.path.join(runs_root, exp_name)\n",
    "        momsub_path = os.path.join(run_dir, \"mom.sub\")\n",
    "\n",
    "        if not os.path.isdir(run_dir) or not os.path.exists(momsub_path):\n",
    "            print(f\"[âš ] Skipping {exp_name} â€” no mom.sub found.\")\n",
    "            continue\n",
    "\n",
    "        submit_and_log_job(run_dir, exp_name, log_path=log_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "550f17f9-f2b9-49e5-8d6a-1e7811031604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import csv\n",
    "\n",
    "def cancel_tracked_jobs(log_path=\"submitted_jobs.csv\", dry_run=False):\n",
    "    \"\"\"\n",
    "    Cancel all jobs listed in the log file that are still in the SLURM queue.\n",
    "    \n",
    "    Parameters:\n",
    "        log_path : str â€” path to the job tracking CSV\n",
    "        dry_run  : bool â€” if True, don't actually cancel jobs, just print them\n",
    "    \"\"\"\n",
    "    if not os.path.exists(log_path):\n",
    "        print(\"[âš ] No job log found.\")\n",
    "        return\n",
    "\n",
    "    # Step 1: Load logged job IDs\n",
    "    with open(log_path, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        jobs = [row for row in reader]\n",
    "\n",
    "    if not jobs:\n",
    "        print(\"[â„¹] No jobs to cancel.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Get list of currently active jobs\n",
    "    try:\n",
    "        result = subprocess.run([\"squeue\", \"-h\", \"-o\", \"%A\"], capture_output=True, text=True, check=True)\n",
    "        active_job_ids = set(result.stdout.strip().splitlines())\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"[âŒ] Failed to check running jobs:\", e)\n",
    "        return\n",
    "\n",
    "    # Step 3: Cancel jobs that are still running\n",
    "    canceled = 0\n",
    "    for job in jobs:\n",
    "        job_id = job[\"job_id\"]\n",
    "        if job_id in active_job_ids:\n",
    "            if dry_run:\n",
    "                print(f\"[DRY-RUN] Would cancel job {job_id} ({job['experiment']})\")\n",
    "            else:\n",
    "                print(f\"[ðŸ›‘] Canceling job {job_id} ({job['experiment']})...\")\n",
    "                try:\n",
    "                    subprocess.run([\"scancel\", job_id], check=True)\n",
    "                    canceled += 1\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    print(f\"[âš ] Failed to cancel job {job_id}: {e}\")\n",
    "        else:\n",
    "            print(f\"[âœ“] Job {job_id} ({job['experiment']}) is no longer running.\")\n",
    "\n",
    "    print(f\"[âœ…] Done. {canceled} job(s) canceled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "264feaa8-ed4b-4f45-9413-95e1dbc6cff0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sbatch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_all_experiments_with_tracking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruns_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRUNS_DIR\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 16\u001b[0m, in \u001b[0;36mrun_all_experiments_with_tracking\u001b[0;34m(runs_root, log_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[âš ] Skipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m â€” no mom.sub found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43msubmit_and_log_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m, in \u001b[0;36msubmit_and_log_job\u001b[0;34m(run_dir, exp_name, log_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit_and_log_job\u001b[39m(run_dir, exp_name, log_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmitted_jobs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msbatch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmom.sub\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/ext3/miniforge/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    501\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/ext3/miniforge/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/ext3/miniforge/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sbatch'"
     ]
    }
   ],
   "source": [
    "run_all_experiments_with_tracking(runs_root=RUNS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a38c5-d3c6-4e5e-af44-bb91b9d104fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FileNotFoundError: [Errno 2] No such file or directory: 'sbatch'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
