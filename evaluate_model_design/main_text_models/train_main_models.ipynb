{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14cbae1-61e6-4bc4-bf31-9608f466725e",
   "metadata": {},
   "source": [
    "# Training main text models\n",
    "\n",
    "Here we train the 3 models that will be used in the main text. \n",
    "\n",
    "Differences: 3 stencil sizes: 1X1, 3X3, 5X5.\n",
    "\n",
    "Common features:\n",
    "- Trained on DG and P2L simulataneously.\n",
    "- Trained on all filter scales at once.\n",
    "- vel grads and thickness grads as inputs\n",
    "- Rotated in and out\n",
    "- 0 - 2048 training.\n",
    "- Model shape [48,48,2] - will make slightly different model sizes, but generally parameter number increases with stencil size, which is what we would like.\n",
    "- Non dim inputs and outputs\n",
    "- MAE loss function\n",
    "- Adam loss function with LR 0.01\n",
    "- Num epochs chosen by stopping at 0.001 stabalize in loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c8504e-8325-4a53-abbb-efde88cc7627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 17:16:19.862000: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-28 17:16:19.875908: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-28 17:16:19.880041: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../modules/')\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import datasets\n",
    "import ML_classes\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec9feb-ddb7-4fb1-8b15-c267b348f0bb",
   "metadata": {},
   "source": [
    "## Setup experiment\n",
    "\n",
    "We use the non-dim training here. This is so that the model can easily focus on data from both experiments.\n",
    "\n",
    "The tests done in folder comparing dim and non-dim showed that non-dim and dim models can have similar skill. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2f394b-b269-43ab-b566-fe93aec60fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need one place to save all the experiment relevant info.  \n",
    "common_config= {'simulation_names':['DG','P2L'], \n",
    "                    'filter_scales':['50','100','200','400'],\n",
    "                    #'filter_scales':['100'],\n",
    "                    #'window_size':3, \n",
    "                    'all_ml_variables' : ['dudx_widened_rotated_nondim',  # must include all variables, including those used as coefficients\n",
    "                                          'dvdx_widened_rotated_nondim', \n",
    "                                          'dudy_widened_rotated_nondim',\n",
    "                                          'dvdy_widened_rotated_nondim',\n",
    "                                          'dhdx_widened_rotated_nondim',\n",
    "                                          'dhdy_widened_rotated_nondim',\n",
    "                                          'uphp_rotated_nondim',  # this non-dim has taken a particular form (see in paper, flux/L^2/|grad u|)\n",
    "                                          'vphp_rotated_nondim'], \n",
    "                    \n",
    "                    'input_channels' :   ['dudx_widened_rotated_nondim',  \n",
    "                                          'dvdx_widened_rotated_nondim', \n",
    "                                          'dudy_widened_rotated_nondim',\n",
    "                                          'dvdy_widened_rotated_nondim',\n",
    "                                          'dhdx_widened_rotated_nondim',\n",
    "                                          'dhdy_widened_rotated_nondim'],\n",
    "                    \n",
    "                    'output_channels' :  ['uphp_rotated_nondim',\n",
    "                                          'vphp_rotated_nondim'],\n",
    "                    \n",
    "                    'coeff_channels'  : [], \n",
    "\n",
    "                    'extra_channels'   : [  'uphp_rotated',\n",
    "                                            'vphp_rotated', \n",
    "                                            'mag_nabla_h_widened',\n",
    "                                            'mag_nabla_u_widened',\n",
    "                                            'filter_scale'],\n",
    "\n",
    "                    'use_coeff_channels': False,\n",
    "                    'single_layer_mask': True,\n",
    "\n",
    "                    'all_time_range': slice(0, 3600),\n",
    "                    'train_time_range': slice(0, 2048),\n",
    "                    'test_time_range' : slice(-128, None),\n",
    "                    'eval_time_range' : slice(-256, -128),\n",
    "                    'num_train_batches': 128, \n",
    "                    'num_test_batches' : 8, \n",
    "\n",
    "                    #'num_inputs': 55, \n",
    "                    'network_shape': [48, 48, 2],\n",
    "\n",
    "                    'ckpt_save_dir': '/home/jovyan/mesoscale_buoyancy_param_ML/ML_checkpoints/main_models/window_all/shape_48_48_2/'\n",
    "                    \n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e71d61-8b09-47b3-b87a-87639e94b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_configs = {'1point':{'window_size':1, 'num_inputs':6, 'exp_ckpt_save_dir': common_config['ckpt_save_dir']+'1point', 'nc_file': 'main_ANN_window_1.nc'},\n",
    "                      '3point':{'window_size':3, 'num_inputs':3*3*6, 'exp_ckpt_save_dir': common_config['ckpt_save_dir']+'3point', 'nc_file': 'main_ANN_window_3.nc'},\n",
    "                      '5point':{'window_size':5, 'num_inputs':5*5*6, 'exp_ckpt_save_dir': common_config['ckpt_save_dir']+'5point', 'nc_file': 'main_ANN_window_5.nc'}    \n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e29b99-7d6a-4799-9512-9c24511341e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08d23e-cfa1-413b-af49-6de89ebf81d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load in DT for: 1point\n"
     ]
    }
   ],
   "source": [
    "#DT = datasets.SimulationData(simulation_names=['P2L', 'DG'], filter_scales=['50','100','200','400'])\n",
    "#for key in experiment_configs.keys():\n",
    "for key in ['1point']:#experiment_configs.keys():\n",
    "\n",
    "    print('Starting to load in DT for: ' + key)\n",
    "    DT = datasets.SimulationData(simulation_names=common_config['simulation_names'], \n",
    "                         filter_scales=common_config['filter_scales'], \n",
    "                         window_size = experiment_configs[key]['window_size'], \n",
    "                         time_sel = common_config['all_time_range'],\n",
    "                         single_layer_mask_flag=common_config['single_layer_mask']\n",
    "                         )\n",
    "\n",
    "    print('Starting to load in ML-DT for: ' + key)\n",
    "    ML_DT_train = datasets.MLXarrayDataset(simulation_data=DT, \n",
    "                                       all_ml_variables=common_config['all_ml_variables'],\n",
    "                                       time_range=common_config['train_time_range'],\n",
    "                                       num_batches = common_config['num_train_batches'],\n",
    "                                       choose_experiment=common_config['simulation_names'])\n",
    "\n",
    "    ML_DT_test = datasets.MLXarrayDataset(simulation_data=DT, \n",
    "                                       all_ml_variables=common_config['all_ml_variables'],\n",
    "                                       time_range=common_config['test_time_range'],\n",
    "                                       num_batches = common_config['num_test_batches'],\n",
    "                                       choose_experiment=common_config['simulation_names'])\n",
    "\n",
    "    train_ML_data = datasets.MLJAXDataset(ML_DT_train, \n",
    "                                      input_channels=common_config['input_channels'], \n",
    "                                      output_channels=common_config['output_channels'], \n",
    "                                      coeff_channels=common_config['coeff_channels'], \n",
    "                                      use_coeff_channels=common_config['use_coeff_channels'],\n",
    "                                      do_normalize=True)\n",
    "\n",
    "    test_ML_data = datasets.MLJAXDataset(ML_DT_test, \n",
    "                                      input_channels=common_config['input_channels'], \n",
    "                                      output_channels=common_config['output_channels'], \n",
    "                                      coeff_channels=common_config['coeff_channels'], \n",
    "                                      use_coeff_channels=common_config['use_coeff_channels'],\n",
    "                                      do_normalize=True)\n",
    "\n",
    "    ML_data_combo = {'train_data':train_ML_data, 'test_data':test_ML_data}\n",
    "\n",
    "    ANN_model = ML_classes.PointwiseANN(num_in = experiment_configs[key]['num_inputs'],\n",
    "                                        shape  = common_config['network_shape'],\n",
    "                                        random_key=1) \n",
    "\n",
    "    print('Num parameters to train ' + str(ANN_model.count_parameters()) + ' for ' + key)\n",
    "          \n",
    "    regress_sys = ML_classes.AnnRegressionSystem(ANN_model, loss_type='mae')\n",
    "\n",
    "    print('Start training: ', key)\n",
    "               \n",
    "    regress_sys.train_system(ML_data_combo, num_epoch=501, print_freq=20, min_relative_improvement=1e-3)\n",
    "\n",
    "    experiment_configs[key]['regress_sys'] = regress_sys\n",
    "\n",
    "    regress_sys.save_checkpoint(experiment_configs[key]['exp_ckpt_save_dir'])\n",
    "\n",
    "    regress_sys.save_nc(nc_fname = experiment_configs[key]['nc_file'], \n",
    "                    ML_DT_train=ML_DT_train, \n",
    "                    input_channels = common_config['input_channels'],\n",
    "                    output_channels = common_config['output_channels'],\n",
    "                    ckpt_save_dir = experiment_configs[key]['exp_ckpt_save_dir'])\n",
    "\n",
    "    print('NC file with weights saved')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ede0e9-d854-4b12-b4e6-53792974cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT.simulation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eaf76c2-00df-46fd-b820-6ddc65460e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load in DT for: 5point\n",
      "Starting to load in ML-DT for: 5point\n",
      "Will load : 20.60402688 gb into memory.\n",
      "load took: 262.5847 seconds\n",
      "Will load : 1.28775168 gb into memory.\n",
      "load took: 21.2812 seconds\n",
      "Num parameters to train 9698 for 5point\n",
      "Start training:  5point\n",
      "At epoch 1. Train loss :  0.2016762198181823 , Test loss: 0.1717205662280321 , Test R2: 0.28902073204517365\n",
      "At epoch 21. Train loss :  0.13135792315006256 , Test loss: 0.1304002981632948 , Test R2: 0.5076948404312134\n",
      "At epoch 41. Train loss :  0.12491731037152931 , Test loss: 0.12446333561092615 , Test R2: 0.535236306488514\n",
      "At epoch 61. Train loss :  0.12153919332195073 , Test loss: 0.12067019566893578 , Test R2: 0.5504225492477417\n",
      "At epoch 81. Train loss :  0.11968319810694084 , Test loss: 0.11972715519368649 , Test R2: 0.5584119036793709\n",
      "Early stopping at epoch 98. No improvement in 10 epochs.\n",
      "Restored best model with smoothed test loss 0.118132\n"
     ]
    }
   ],
   "source": [
    "#DT = datasets.SimulationData(simulation_names=['P2L', 'DG'], filter_scales=['50','100','200','400'])\n",
    "for key in ['5point']:\n",
    "\n",
    "    print('Starting to load in DT for: ' + key)\n",
    "    DT = datasets.SimulationData(simulation_names=common_config['simulation_names'], \n",
    "                         filter_scales=common_config['filter_scales'], \n",
    "                         window_size = experiment_configs[key]['window_size'], \n",
    "                         time_sel = common_config['all_time_range'],\n",
    "                         single_layer_mask_flag=common_config['single_layer_mask']\n",
    "                         )\n",
    "\n",
    "    print('Starting to load in ML-DT for: ' + key)\n",
    "    ML_DT_train = datasets.MLXarrayDataset(simulation_data=DT, \n",
    "                                       all_ml_variables=common_config['all_ml_variables'],\n",
    "                                       time_range=common_config['train_time_range'],\n",
    "                                       num_batches = common_config['num_train_batches'],\n",
    "                                       choose_experiment=common_config['simulation_names'])\n",
    "\n",
    "    ML_DT_test = datasets.MLXarrayDataset(simulation_data=DT, \n",
    "                                       all_ml_variables=common_config['all_ml_variables'],\n",
    "                                       time_range=common_config['test_time_range'],\n",
    "                                       num_batches = common_config['num_test_batches'],\n",
    "                                       choose_experiment=common_config['simulation_names'])\n",
    "\n",
    "    train_ML_data = datasets.MLJAXDataset(ML_DT_train, \n",
    "                                      input_channels=common_config['input_channels'], \n",
    "                                      output_channels=common_config['output_channels'], \n",
    "                                      coeff_channels=common_config['coeff_channels'], \n",
    "                                      use_coeff_channels=common_config['use_coeff_channels'],\n",
    "                                      do_normalize=True)\n",
    "\n",
    "    test_ML_data = datasets.MLJAXDataset(ML_DT_test, \n",
    "                                      input_channels=common_config['input_channels'], \n",
    "                                      output_channels=common_config['output_channels'], \n",
    "                                      coeff_channels=common_config['coeff_channels'], \n",
    "                                      use_coeff_channels=common_config['use_coeff_channels'],\n",
    "                                      do_normalize=True)\n",
    "\n",
    "    ML_data_combo = {'train_data':train_ML_data, 'test_data':test_ML_data}\n",
    "\n",
    "    ANN_model = ML_classes.PointwiseANN(num_in = experiment_configs[key]['num_inputs'],\n",
    "                                        shape  = common_config['network_shape'],\n",
    "                                        random_key=1) \n",
    "\n",
    "    print('Num parameters to train ' + str(ANN_model.count_parameters()) + ' for ' + key)\n",
    "          \n",
    "    regress_sys = ML_classes.AnnRegressionSystem(ANN_model, loss_type='mae')\n",
    "\n",
    "    print('Start training: ', key)\n",
    "               \n",
    "    regress_sys.train_system(ML_data_combo, num_epoch=501, print_freq=20, min_relative_improvement=1e-3)\n",
    "\n",
    "    experiment_configs[key]['regress_sys'] = regress_sys\n",
    "\n",
    "    regress_sys.save_checkpoint(experiment_configs[key]['exp_ckpt_save_dir'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ff063-638c-463c-9e9f-a0dbd1b75e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b1cb9-0389-4b9a-809d-6d1f63c65df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
