{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14cbae1-61e6-4bc4-bf31-9608f466725e",
   "metadata": {},
   "source": [
    "# Training main text models\n",
    "\n",
    "Here we train the 3 models that will be used in the main text. \n",
    "\n",
    "Differences: 3 stencil sizes: 1X1, 3X3, 5X5.\n",
    "\n",
    "Common features:\n",
    "- Trained on DG and P2L simulataneously.\n",
    "- Trained on all filter scales at once.\n",
    "- vel grads and thickness grads as inputs\n",
    "- Rotated in and out\n",
    "- 0 - 2048 training.\n",
    "- Model shape [48,48,2] - will make slightly different model sizes, but generally parameter number increases with stencil size, which is what we would like.\n",
    "- Non dim inputs and outputs\n",
    "- MAE loss function\n",
    "- Adam loss function with LR 0.01\n",
    "- Num epochs chosen by stopping at 0.001 stabalize in loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c8504e-8325-4a53-abbb-efde88cc7627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 21:29:58.507040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-22 21:29:58.521684: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-22 21:29:58.526008: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../modules/')\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import datasets\n",
    "import ML_classes\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec9feb-ddb7-4fb1-8b15-c267b348f0bb",
   "metadata": {},
   "source": [
    "## Setup experiment\n",
    "\n",
    "We use the non-dim training here. This is so that the model can easily focus on data from both experiments.\n",
    "\n",
    "The tests done in folder comparing dim and non-dim showed that non-dim and dim models can have similar skill. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2f394b-b269-43ab-b566-fe93aec60fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need one place to save all the experiment relevant info.  \n",
    "common_config= {'simulation_names':['DG','P2L'], \n",
    "                    'filter_scales':['50','100','200','400'],\n",
    "                    #'filter_scales':['100'],\n",
    "                    #'window_size':3, \n",
    "                    'all_ml_variables' : ['dudx_widened_rotated_nondim',  # must include all variables, including those used as coefficients\n",
    "                                          'dvdx_widened_rotated_nondim', \n",
    "                                          'dudy_widened_rotated_nondim',\n",
    "                                          'dvdy_widened_rotated_nondim',\n",
    "                                          'dhdx_widened_rotated_nondim',\n",
    "                                          'dhdy_widened_rotated_nondim',\n",
    "                                          'uphp_rotated_nondim',  # this non-dim has taken a particular form (see in paper, flux/L^2/|grad u|)\n",
    "                                          'vphp_rotated_nondim'], \n",
    "                    \n",
    "                    'input_channels' :   ['dudx_widened_rotated_nondim',  \n",
    "                                          'dvdx_widened_rotated_nondim', \n",
    "                                          'dudy_widened_rotated_nondim',\n",
    "                                          'dvdy_widened_rotated_nondim',\n",
    "                                          'dhdx_widened_rotated_nondim',\n",
    "                                          'dhdy_widened_rotated_nondim'],\n",
    "                    \n",
    "                    'output_channels' :  ['uphp_rotated_nondim',\n",
    "                                          'vphp_rotated_nondim'],\n",
    "                    \n",
    "                    'coeff_channels'  : [], \n",
    "\n",
    "                    'extra_channels'   : [  'uphp_rotated',\n",
    "                                            'vphp_rotated', \n",
    "                                            'mag_nabla_h_widened',\n",
    "                                            'mag_nabla_u_widened',\n",
    "                                            'filter_scale'],\n",
    "\n",
    "                    'use_coeff_channels': False,\n",
    "                    'single_layer_mask': True,\n",
    "\n",
    "                    'all_time_range': slice(0, 3600),\n",
    "                    'train_time_range': slice(0, 2048),\n",
    "                    'test_time_range' : slice(-128, None),\n",
    "                    'eval_time_range' : slice(-256, -128),\n",
    "                    'num_train_batches': 128, \n",
    "                    'num_test_batches' : 8, \n",
    "\n",
    "                    #'num_inputs': 55, \n",
    "                    'network_shape': [48, 48, 2],\n",
    "\n",
    "                    'ckpt_save_dir': '/home/jovyan/mesoscale_buoyancy_param_ML/ML_checkpoints/main_models/window_3/shape_48_48_2/'\n",
    "                    \n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e71d61-8b09-47b3-b87a-87639e94b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_configs = {'1point':{'window_size':1, 'num_inputs':6, 'exp_ckpt_save_dir': common_config['ckpt_save_dir']+'1point'},\n",
    "                      '3point':{'window_size':3, 'num_inputs':3*3*6, 'exp_ckpt_save_dir': common_config['ckpt_save_dir']+'3point'},\n",
    "                      '5point':{'window_size':5, 'num_inputs':5*5*6, 'exp_ckpt_save_dir': common_config['ckpt_save_dir']+'5point'}    \n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df951613-1311-4b32-aa03-1b6e9eccbd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd0f8b-3f5a-41e4-9374-9008b858b3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e29b99-7d6a-4799-9512-9c24511341e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08d23e-cfa1-413b-af49-6de89ebf81d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load in DT for: 1point\n",
      "Starting to load in ML-DT for: 1point\n",
      "Will load : 1.70606592 gb into memory.\n",
      "load took: 46.3920 seconds\n",
      "Will load : 0.10662912 gb into memory.\n",
      "load took: 4.5018 seconds\n",
      "Num parameters to train 2786 for 1point\n",
      "Start training:  1point\n",
      "At epoch 1. Train loss :  0.4628345638047904 , Test loss: 0.45763134583830833 , Test R2: -1.119167536497116\n",
      "At epoch 21. Train loss :  0.45518867764621973 , Test loss: 0.4552800618112087 , Test R2: -1.1178016662597656\n",
      "Early stopping at epoch 25. No improvement in 10 epochs.\n",
      "Restored best model with smoothed test loss 0.455523\n",
      "Starting to load in DT for: 3point\n",
      "Starting to load in ML-DT for: 3point\n",
      "Will load : 8.00538624 gb into memory.\n",
      "load took: 134.1020 seconds\n",
      "Will load : 0.50033664 gb into memory.\n",
      "load took: 10.8898 seconds\n",
      "Num parameters to train 5090 for 3point\n",
      "Start training:  3point\n",
      "At epoch 1. Train loss :  0.24254556372761726 , Test loss: 0.21503141149878502 , Test R2: 0.0999240055680275\n",
      "At epoch 21. Train loss :  0.18010591622442007 , Test loss: 0.1802458930760622 , Test R2: 0.26771487295627594\n",
      "At epoch 41. Train loss :  0.17446574242785573 , Test loss: 0.17290109768509865 , Test R2: 0.30051256716251373\n",
      "At epoch 61. Train loss :  0.17136084393132478 , Test loss: 0.17014254070818424 , Test R2: 0.3118700161576271\n",
      "Early stopping at epoch 78. No improvement in 10 epochs.\n",
      "Restored best model with smoothed test loss 0.169701\n",
      "Starting to load in DT for: 5point\n"
     ]
    }
   ],
   "source": [
    "#DT = datasets.SimulationData(simulation_names=['P2L', 'DG'], filter_scales=['50','100','200','400'])\n",
    "for key in experiment_configs.keys():\n",
    "\n",
    "    print('Starting to load in DT for: ' + key)\n",
    "    DT = datasets.SimulationData(simulation_names=common_config['simulation_names'], \n",
    "                         filter_scales=common_config['filter_scales'], \n",
    "                         window_size = experiment_configs[key]['window_size'], \n",
    "                         time_sel = common_config['all_time_range'],\n",
    "                         single_layer_mask_flag=common_config['single_layer_mask']\n",
    "                         )\n",
    "\n",
    "    print('Starting to load in ML-DT for: ' + key)\n",
    "    ML_DT_train = datasets.MLXarrayDataset(simulation_data=DT, \n",
    "                                       all_ml_variables=common_config['all_ml_variables'],\n",
    "                                       time_range=common_config['train_time_range'],\n",
    "                                       num_batches = common_config['num_train_batches'],\n",
    "                                       choose_experiment=common_config['simulation_names'])\n",
    "\n",
    "    ML_DT_test = datasets.MLXarrayDataset(simulation_data=DT, \n",
    "                                       all_ml_variables=common_config['all_ml_variables'],\n",
    "                                       time_range=common_config['test_time_range'],\n",
    "                                       num_batches = common_config['num_test_batches'],\n",
    "                                       choose_experiment=common_config['simulation_names'])\n",
    "\n",
    "    train_ML_data = datasets.MLJAXDataset(ML_DT_train, \n",
    "                                      input_channels=common_config['input_channels'], \n",
    "                                      output_channels=common_config['output_channels'], \n",
    "                                      coeff_channels=common_config['coeff_channels'], \n",
    "                                      use_coeff_channels=common_config['use_coeff_channels'],\n",
    "                                      do_normalize=True)\n",
    "\n",
    "    test_ML_data = datasets.MLJAXDataset(ML_DT_test, \n",
    "                                      input_channels=common_config['input_channels'], \n",
    "                                      output_channels=common_config['output_channels'], \n",
    "                                      coeff_channels=common_config['coeff_channels'], \n",
    "                                      use_coeff_channels=common_config['use_coeff_channels'],\n",
    "                                      do_normalize=True)\n",
    "\n",
    "    ML_data_combo = {'train_data':train_ML_data, 'test_data':test_ML_data}\n",
    "\n",
    "    ANN_model = ML_classes.PointwiseANN(num_in = experiment_configs[key]['num_inputs'],\n",
    "                                        shape  = common_config['network_shape'],\n",
    "                                        random_key=1) \n",
    "\n",
    "    print('Num parameters to train ' + str(ANN_model.count_parameters()) + ' for ' + key)\n",
    "          \n",
    "    regress_sys = ML_classes.AnnRegressionSystem(ANN_model, loss_type='mae')\n",
    "\n",
    "    print('Start training: ', key)\n",
    "               \n",
    "    regress_sys.train_system(ML_data_combo, num_epoch=501, print_freq=20, min_relative_improvement=1e-3)\n",
    "\n",
    "    experiment_configs[key]['regress_sys'] = regress_sys\n",
    "\n",
    "    regress_sys.save_checkpoint(experiment_configs[key]['exp_ckpt_save_dir'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf76c2-00df-46fd-b820-6ddc65460e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load in DT for: 5point\n"
     ]
    }
   ],
   "source": [
    "#DT = datasets.SimulationData(simulation_names=['P2L', 'DG'], filter_scales=['50','100','200','400'])\n",
    "for key in ['5point']:\n",
    "\n",
    "    print('Starting to load in DT for: ' + key)\n",
    "    DT = datasets.SimulationData(simulation_names=common_config['simulation_names'], \n",
    "                         filter_scales=common_config['filter_scales'], \n",
    "                         window_size = experiment_configs[key]['window_size'], \n",
    "                         time_sel = common_config['all_time_range'],\n",
    "                         single_layer_mask_flag=common_config['single_layer_mask']\n",
    "                         )\n",
    "\n",
    "    print('Starting to load in ML-DT for: ' + key)\n",
    "    ML_DT_train = datasets.MLXarrayDataset(simulation_data=DT, \n",
    "                                       all_ml_variables=common_config['all_ml_variables'],\n",
    "                                       time_range=common_config['train_time_range'],\n",
    "                                       num_batches = common_config['num_train_batches'],\n",
    "                                       choose_experiment=common_config['simulation_names'])\n",
    "\n",
    "    ML_DT_test = datasets.MLXarrayDataset(simulation_data=DT, \n",
    "                                       all_ml_variables=common_config['all_ml_variables'],\n",
    "                                       time_range=common_config['test_time_range'],\n",
    "                                       num_batches = common_config['num_test_batches'],\n",
    "                                       choose_experiment=common_config['simulation_names'])\n",
    "\n",
    "    train_ML_data = datasets.MLJAXDataset(ML_DT_train, \n",
    "                                      input_channels=common_config['input_channels'], \n",
    "                                      output_channels=common_config['output_channels'], \n",
    "                                      coeff_channels=common_config['coeff_channels'], \n",
    "                                      use_coeff_channels=common_config['use_coeff_channels'],\n",
    "                                      do_normalize=True)\n",
    "\n",
    "    test_ML_data = datasets.MLJAXDataset(ML_DT_test, \n",
    "                                      input_channels=common_config['input_channels'], \n",
    "                                      output_channels=common_config['output_channels'], \n",
    "                                      coeff_channels=common_config['coeff_channels'], \n",
    "                                      use_coeff_channels=common_config['use_coeff_channels'],\n",
    "                                      do_normalize=True)\n",
    "\n",
    "    ML_data_combo = {'train_data':train_ML_data, 'test_data':test_ML_data}\n",
    "\n",
    "    ANN_model = ML_classes.PointwiseANN(num_in = experiment_configs[key]['num_inputs'],\n",
    "                                        shape  = common_config['network_shape'],\n",
    "                                        random_key=1) \n",
    "\n",
    "    print('Num parameters to train ' + str(ANN_model.count_parameters()) + ' for ' + key)\n",
    "          \n",
    "    regress_sys = ML_classes.AnnRegressionSystem(ANN_model, loss_type='mae')\n",
    "\n",
    "    print('Start training: ', key)\n",
    "               \n",
    "    regress_sys.train_system(ML_data_combo, num_epoch=501, print_freq=20, min_relative_improvement=1e-3)\n",
    "\n",
    "    experiment_configs[key]['regress_sys'] = regress_sys\n",
    "\n",
    "    regress_sys.save_checkpoint(experiment_configs[key]['exp_ckpt_save_dir'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ff063-638c-463c-9e9f-a0dbd1b75e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b1cb9-0389-4b9a-809d-6d1f63c65df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dd4329f-acdd-4fe7-868c-4c302698346b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'regress_sys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mnum_models))  \n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, set_keys \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(exp_sets\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m----> 7\u001b[0m     regress_sys \u001b[38;5;241m=\u001b[39m \u001b[43mexp_sets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mset_keys\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregress_sys\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \n\u001b[1;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(num_models, \u001b[38;5;241m1\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(regress_sys\u001b[38;5;241m.\u001b[39mtrain_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining loss, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(regress_sys\u001b[38;5;241m.\u001b[39mtrain_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'regress_sys'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Loss plot\n",
    "num_models = len(exp_sets.keys())\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4*num_models))  \n",
    "\n",
    "for i, set_keys in enumerate(exp_sets.keys()):\n",
    "    regress_sys = exp_sets[set_keys]['regress_sys'] \n",
    "    plt.subplot(num_models, 1, i+1)\n",
    "    plt.plot(regress_sys.train_loss, label='Training loss, '+str(regress_sys.train_loss[-1]))\n",
    "    plt.plot(regress_sys.test_loss, label='Test loss'+str(regress_sys.test_loss[-1]))\n",
    "\n",
    "    plt.grid()\n",
    "    plt.yscale('log')\n",
    "    plt.title(exp_sets[set_keys]['sel_sim'])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a0ae62-cf8f-4888-ba58-1deb2933aa1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
